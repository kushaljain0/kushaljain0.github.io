<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Term-GPT - Kushal Jain</title>
    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Kushal Jain</div>
            <ul class="nav-links">
                <li><a href="../index.html#home">Home</a></li>
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../index.html#experience">Experience</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <section class="project-detail">
            <h1>Term-GPT</h1>
            <div class="project-info">
                <div class="project-description">
                    <h2>Overview</h2>
                    <p>Term-GPT is an innovative command-line tool that leverages Large Language Models (LLMs) to translate natural language into executable commands. The project supports multiple AI models including Google Gemini, OpenAI GPT, and Anthropic Claude, providing users with a versatile and powerful interface for command-line operations.</p>
                    
                    <h2>Key Features</h2>
                    <ul>
                        <li>Support for 8+ LLM models including Google Gemini, OpenAI GPT, and Anthropic Claude</li>
                        <li>Fast mode with 1.6-second response times</li>
                        <li>Offline functionality through quantized models</li>
                        <li>50% reduction in API call costs through optimized model selection</li>
                        <li>Rate-limiting usage across devices without GPUs</li>
                    </ul>

                    <h2>Technical Details</h2>
                    <p>The project implements a sophisticated model selection algorithm that optimizes for both performance and cost. It uses quantized models for offline functionality while maintaining high accuracy in command translation. The system is designed to work efficiently even on devices without dedicated GPUs.</p>

                    <h2>Technologies Used</h2>
                    <ul>
                        <li>Python</li>
                        <li>LLM APIs (Google Gemini, OpenAI GPT, Anthropic Claude)</li>
                        <li>Model Quantization</li>
                        <li>Command Line Interface Development</li>
                    </ul>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="footer-content">
            <div class="social-links">
                <a href="https://github.com/kushaljain0" target="_blank"><i class="fab fa-github"></i></a>
                <a href="https://www.linkedin.com/in/kushaljain0" target="_blank"><i class="fab fa-linkedin"></i></a>
                <a href="https://codeforces.com/profile/kushaljain0" target="_blank"><i class="fas fa-code"></i></a>
            </div>
            <p>&copy; 2024 Kushal Jain. All rights reserved.</p>
        </div>
    </footer>
</body>
</html> 